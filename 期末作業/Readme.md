聲明:此筆記是收集網路上的資料後與ChatGPT共同編寫而成。

參考資料:
https://pansci.asia/archives/361905
https://ir.nctu.edu.tw/bitstream/11536/155867/1/information%20society4103.pdf
https://philomedium.com/blog/81477
https://blog.twnic.tw/2022/05/16/22994/
https://ethics.moe.edu.tw/files/resource/ebook/file/ebook_01_cn.pdf

倫理與人工智慧：探索道德挑戰與解決方案

導言：
人工智慧（Artificial Intelligence，簡稱AI）的快速發展與應用引發了許多倫理問題與道德挑戰。在這份筆記中，我們將探討倫理與人工智慧之間的關係，深入探討相關倫理挑戰，並提出可能的解決方案。

風險:

演算法偏誤:
第一種是演算法偏誤（algorithmic bias）。什麼是演算法偏誤？簡單來說就是 AI 在某些群體的判斷準確率或預測結果上總是很差，導致結果可能對於此群體造成系統性的不利。但為何會造成演算法偏誤？常見原因有三項。

第一項原因是，建立 AI 模型的研究資料集有偏誤，在性別、種族、社經地位等特徵上，沒有真實世界的人口分布代表性。例如數位裝置採用 AI 臉部辨識技術解鎖，原本是希望保護個人使用數位裝置的安全性，結果皮膚深的人卻常常遇到辨識失敗而無法解鎖。這通常是因為目前許多 AI 模型都是以機器學習技術設計，而機器學習的主要特性就是從過去人類留下的大量資料中學習；當初提供電腦學習臉部辨識的圖片時，如果多數都是白皮膚而非黑皮膚、多數都是男性的臉而非女性的臉，那麼電腦在學習辨識人臉的準確率上，整體而言辨識男性白人就會比辨識女性黑人要高出許多。

第二項產生演算法偏誤的原因是建立 AI 模型的研究資料集不只有偏誤，還反映現實社會中的性別、種族、社經地位等歧視；例如美國警政單位以過往犯罪資料訓練出獄後犯人再犯風險評估的 AI 模型，那些資料不意外地有色人種的犯罪紀錄遠多於白人犯罪紀錄。然而，那些紀錄也反映美國社會長久以來對於有色人種的歧視，其中包含警察對於有色人種的盤查比例遠高於白人、法院對於有色人種的定罪比例及判刑嚴重程度也遠高於白人、警力通常被派往多黑人與拉丁裔人種居住的窮困社區盤查等。所以根據過往犯罪資料所訓練出來的 AI 模型，不意外地也就會預測有色人種的再犯機率普遍來說比白人高。

第三項產生演算法偏誤的原因則是 AI 學會了連系統開發者都沒有察覺到，潛藏在資料裡的偏誤。例如科技公司人資部門本來想借助 AI 更有效率地篩選出適合來面試的履歷，所以挑選在該公司任職一定年資且曾升遷二次的員工履歷來訓練 AI 模型。問題是，高科技公司向來男多女少，所提供給 AI 學習的資料自然就男女比例相當不均。AI 也就學會了凡是出現偏向女性名字、嗜好、畢業學校系所等文字的履歷，平均所給的評分都比出現偏向男性等相關文字的履歷還低。

但目前科技公司陽盛陰衰，是受到以往鼓勵男性就讀理工、女性就讀人文科系，或男性在外工作女性在家帶小孩等性別刻板偏見所影響。所以 20～30 年來許多人做出各種努力以消除這種性別刻板偏見所帶來的不良影響，政府也努力制定各種政策來消除這種不當的性別偏見，像是求才廣告基本上不能限定性別、公司聘雇員工應該達到一定的性別比例等。因此，訓練 AI 的研究資料一旦隱藏類似前述性別比例不均的現象，訓練出來的 AI 預測結果就彷彿帶有性別歧視，讓人們過往致力消除性別不平等的各種努力都白費了。

除了演算法偏誤的問題外，第二種可能帶來的倫理問題或風險是 AI 技術已經偏離原先使用目的，例如深偽技術（deepfake）原本用來解決圖片資料量不夠的問題，後來卻被利用在偽造名人性愛影片等。

第三種則是有些 AI 技術或產品本身就可能有善惡兩種用途（dual-use）。例如 AI 人臉辨識技術可用在保護數位裝置的使用者或大樓保全，但也可用來窺探或監控特定個人；無人機可以在農業上幫助農夫播種，但也可作為自動殺人武器；可用來搜尋如何產生毒性最少的藥物合成演算法，也能反過來成為搜尋如何產生毒性最強的藥物合成演算法。

最後，第四種是演算法設計不良或現有技術限制所導致的問題。在演算法設計不良方面，例如下棋機器人手臂可能因為沒有設計施力回饋或移動受阻暫停等防呆裝置，而造成誤抓人類棋手的手指且弄斷的意外。在現有技術限制方面，道路駕駛的交通標誌在現實中可能時常有老舊或髒汙的情況，儘管對於人類駕駛來說可能不影響判讀，但對於自駕車來說很可能就因此會嚴重誤判，例如無法正確辨識禁止通行標誌而繼續行駛，或是將速限 35 公里誤判成 85 公里等。但前述情況也有可能是自駕車網路、控制權限或物件辨識模型受到惡意攻擊所致。

倫理與敏銳度 (對AI) :

近五、六年來國際組織如聯合國教育科學及文化組織（United Nations Educational, Scientific and Cultural Organization, UNESCO）、歐盟（European Union, EU）、電機電子工程師學會（Institute of Electrical and Electronics Engineers, IEEE）或是國家、國際非營利組織皆紛紛制訂有關 AI 發展的白皮書或倫理指引（ethical guidelines），甚至逐漸朝向法律治理的方向，如歐盟的人工智慧規則草案等。儘管這些文件所提出的倫理價值、原則或行為規範，看似各有不同，但經過這些年的討論與摸索，也逐漸匯聚出一些共識。

臺灣相較於前述國際文件來說，在制訂的時間上比較晚。2019 年由當時的科技部（現改為國科會）制訂「人工智慧科研發展指引」，裡面提出的三項倫理價值以及八項行為指引，基本上涵蓋了前述各種國際 AI 發展指引文件最常提及的內容。所謂三項倫理價值包含以人為本、永續發展、多元包容，行為指引則有共榮共利、安全性、問責與溝通、自主權與控制權、透明性與可追溯性、可解釋性、個人隱私與數據治理、公平性與非歧視性共八項。

未來當讀者看到又出現哪些 AI 新技術或產品時，不妨試著評估看看是否有符合這三項價值及八項行為指引。若沒有，究竟是哪項不符合？不符合的原因是上述所介紹常見的四種倫理問題或風險的哪一種？若都不是，還有哪些倫理問題或風險過去被忽略了但值得重視？

AI 技術發展日新月進，在日常生活中的應用也愈來愈廣。但考量法律條文有強制性，在制訂時必須相當謹慎，免得動輒得咎，也很可能在不清楚狀況下反而制訂了不當阻礙創新發展的條文；再加上法律制定也必須有一定的穩定性，不能朝令夕改，否則會讓遵守法規者無所適從。因此可以想見，法令規範趕不上新興科技所帶來的問題與風險本來就是常態，而非遇到 AI 科技才有這種情況。

人們若能培養自身對於 AI 倫理問題或風險的敏銳度，便可發揮公民監督或協助政府監督的力量，評估 AI 開發或使用者有無善盡避免傷害特定個人或群體之嫌，逐漸改善 AI 開發者與大眾媒體常過度誇大 AI 功能，但對於可能帶來的倫理問題或風險卻常閃爍其詞或避而不談的不好現象。

倫理挑戰：

個人隱私保護：隨著AI技術能夠蒐集和分析大量個人數據，個人隱私成為一個重要關切。我們需要確保在利用AI技術的同時，保護個人隱私和資料安全。建立合適的隱私保護機制，例如強化數據匿名化和加密技術，以減少個人資料遭到濫用的風險。

不平等和歧視：AI系統的設計和執行受到開發者和訓練數據的影響，這可能導致系統存在潛在的偏見和歧視。我們應該確保AI技術的公平性和無歧視性，並避免將社會不平等進一步深化。這需要開發者在數據收集和模型設計階段引入多元性，並進行系統性的監測和評估。

自主性與責任：隨著AI系統變得越來越自主，問題出現在當系統做出錯誤決策或引發不良後果時該如何負責。明確界定人工智慧系統的責任和義務是一個具有挑戰性的倫理問題。我們需要建立適當的法律和道德框架，確定人工智慧系統的使用者、開發者和監管者在不同情況下的責任分配，並建立追溯和追究機制。

解決方案：

倫理設計：將倫理原則納入AI系統的設計過程中，確保系統遵循道德準則。這包括建立多元化的開發團隊，以確保不同觀點和價值觀的納入，並加強監管和規範以確保系統的公正性和透明度。同時，倫理設計應該成為AI相關課程和培訓的一部分，培養AI專業人員的倫理意識和道德判斷能力。

透明度和可解釋性：提高AI系統的透明度和可解釋性，使用戶和利害關係人能夠理解系統是如何作出決策的。這有助於消除不公平和偏見，增加對系統的信任。透明度的實現可以通過公開算法和模型，以及提供清晰的解釋來實現。

法律和監管：建立相關的法律和監管框架，確保AI技術的使用符合倫理和法律要求。這包括制定隱私保護法、反歧視法和專門監管AI的機構。同時，加強國際合作，制定共同的原則和標準，以應對跨境使用AI技術所帶來的倫理問題。

結論：
或許未來有一天，人類真的可以設計出如電影中那些像人一樣的 AI 系統或機器人。但目前為止，你常聽到的 AI 其實既很厲害又很不厲害，為什麼呢？厲害的是它下圍棋可贏過世界冠軍，還能夠比放射科技師更快、更準確地辨識 X 光片中疑似病變的細胞；但它不厲害的是，很會下圍棋的 AI 就只能下圍棋，別說不會打牌，連撲克牌是什麼都不知道！而且每次學新事物幾乎都是打掉重練，得不斷做好多考古題才有可能學得會，不像人類通常教幾次就會舉一反。

倫理和人工智慧之間的關係是一個複雜且不斷演變的領域。解決人工智慧引發的倫理挑戰需要多方合作，包括政府、業界、學術界和公眾的參與。只有通過合作，我們才能確保人工智慧的發展符合倫理準則，為社會帶來更大的利益，同時尊重個人和社會價值。